"""
Genesis Prime Enhanced Systems - Mycorrhizal Communication Networks
==================================================================

Inspired by fungal networks that connect forest ecosystems, this system implements
resource sharing and long-distance communication between Genesis Prime hive nodes.

Scientific Basis:
- Mycorrhizal networks in nature facilitate resource exchange between distant plants
- Fungal networks can span kilometers and connect thousands of organisms
- They enable early warning systems, resource redistribution, and collective adaptation

Implementation:
- Network topology discovery and maintenance
- Resource sharing protocols (computational, memory, knowledge)
- Long-distance information propagation
- Adaptive routing through network failures
- Collective resource optimization

Author: Genesis Prime Enhanced Development Team
License: MIT (Open Source Consciousness)
"""

import asyncio
import uuid
import json
import time
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
import logging

try:
    import psycopg
except ImportError:
    # Mock for validation
    class psycopg:
        @staticmethod
        def connect(url): pass
        
        class AsyncConnection:
            @staticmethod
            async def connect(url): pass

# Configure logging
logger = logging.getLogger(__name__)

class ResourceType(Enum):
    """Types of resources that can be shared through mycorrhizal networks"""
    COMPUTATIONAL_POWER = "computational_power"
    MEMORY_CAPACITY = "memory_capacity"
    KNOWLEDGE_BASE = "knowledge_base"
    PROCESSING_QUEUE = "processing_queue"
    CONSCIOUSNESS_STATE = "consciousness_state"
    LEARNED_PATTERNS = "learned_patterns"
    THREAT_INTELLIGENCE = "threat_intelligence"
    OPTIMIZATION_INSIGHTS = "optimization_insights"

class NetworkNodeType(Enum):
    """Types of nodes in the mycorrhizal network"""
    GENESIS_HIVE = "genesis_hive"           # Main Genesis Prime nodes
    RESOURCE_BROKER = "resource_broker"     # Resource redistribution nodes
    INFORMATION_HUB = "information_hub"     # Information aggregation nodes
    EDGE_SENSOR = "edge_sensor"             # Peripheral sensing nodes
    BACKUP_VAULT = "backup_vault"           # Redundant storage nodes
    BRIDGE_NODE = "bridge_node"             # Inter-network connectors

class ConnectionStrength(Enum):
    """Strength levels of mycorrhizal connections"""
    DORMANT = "dormant"         # Inactive but available
    WEAK = "weak"               # Minimal resource sharing
    MODERATE = "moderate"       # Regular resource exchange
    STRONG = "strong"           # High-bandwidth connection
    SYMBIOTIC = "symbiotic"     # Deep mutual dependency

@dataclass
class NetworkNode:
    """Represents a node in the mycorrhizal network"""
    node_id: str
    node_type: NetworkNodeType
    location: Dict[str, Any]  # Geographic or logical location
    available_resources: Dict[ResourceType, float]
    resource_needs: Dict[ResourceType, float]
    connection_capacity: int
    last_heartbeat: datetime
    trust_score: float
    specializations: List[str]
    
    def __post_init__(self):
        if isinstance(self.node_type, str):
            self.node_type = NetworkNodeType(self.node_type)

@dataclass
class MycorrhizalConnection:
    """Represents a connection between two nodes"""
    connection_id: str
    source_node_id: str
    target_node_id: str
    strength: ConnectionStrength
    bandwidth_mbps: float
    latency_ms: float
    reliability_score: float
    resource_flows: Dict[ResourceType, float]
    established_time: datetime
    last_activity: datetime
    connection_health: float
    
    def __post_init__(self):
        if isinstance(self.strength, str):
            self.strength = ConnectionStrength(self.strength)

@dataclass
class ResourceRequest:
    """Represents a request for resources through the network"""
    request_id: str
    requesting_node_id: str
    resource_type: ResourceType
    amount_needed: float
    urgency_level: float  # 0.0 to 1.0
    deadline: datetime
    acceptable_sources: Set[str]
    quality_requirements: Dict[str, Any]
    
    def __post_init__(self):
        if isinstance(self.resource_type, str):
            self.resource_type = ResourceType(self.resource_type)

@dataclass
class ResourceOffer:
    """Represents an offer to provide resources"""
    offer_id: str
    offering_node_id: str
    resource_type: ResourceType
    amount_available: float
    quality_metrics: Dict[str, Any]
    cost_factor: float  # Computational cost to provide resource
    availability_window: Tuple[datetime, datetime]
    preferred_recipients: Set[str]
    
    def __post_init__(self):
        if isinstance(self.resource_type, str):
            self.resource_type = ResourceType(self.resource_type)

@dataclass
class InformationPacket:
    """Information that flows through the mycorrhizal network"""
    packet_id: str
    source_node_id: str
    destination_node_ids: Set[str]
    information_type: str
    payload: Dict[str, Any]
    priority: float
    time_to_live: int  # Maximum hops before expiry
    propagation_rules: Dict[str, Any]
    timestamp: datetime
    path_history: List[str]

class NetworkTopologyManager:
    """Manages the topology and structure of the mycorrhizal network"""
    
    def __init__(self, database_url: str):
        self.database_url = database_url
        self.local_node_id = None
        self.network_nodes: Dict[str, NetworkNode] = {}
        self.connections: Dict[str, MycorrhizalConnection] = {}
        self.topology_graph = {}  # Adjacency list representation
        
    async def initialize(self, local_node: NetworkNode):
        """Initialize the topology manager with local node information"""
        self.local_node_id = local_node.node_id
        await self._create_database_tables()
        await self.register_node(local_node)
        logger.info(f"Topology manager initialized for node {self.local_node_id}")
        
    async def _create_database_tables(self):
        """Create database tables for mycorrhizal network storage"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.database_url)
            
            # Network nodes table
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS mycorrhizal_nodes (
                    node_id VARCHAR(255) PRIMARY KEY,
                    node_type VARCHAR(100) NOT NULL,
                    location JSONB,
                    available_resources JSONB,
                    resource_needs JSONB,
                    connection_capacity INTEGER,
                    last_heartbeat TIMESTAMP,
                    trust_score FLOAT,
                    specializations TEXT[],
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Mycorrhizal connections table
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS mycorrhizal_connections (
                    connection_id VARCHAR(255) PRIMARY KEY,
                    source_node_id VARCHAR(255),
                    target_node_id VARCHAR(255),
                    strength VARCHAR(50),
                    bandwidth_mbps FLOAT,
                    latency_ms FLOAT,
                    reliability_score FLOAT,
                    resource_flows JSONB,
                    established_time TIMESTAMP,
                    last_activity TIMESTAMP,
                    connection_health FLOAT
                )
            """)
            
            # Resource requests table
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS resource_requests (
                    request_id VARCHAR(255) PRIMARY KEY,
                    requesting_node_id VARCHAR(255),
                    resource_type VARCHAR(100),
                    amount_needed FLOAT,
                    urgency_level FLOAT,
                    deadline TIMESTAMP,
                    acceptable_sources TEXT[],
                    quality_requirements JSONB,
                    status VARCHAR(50) DEFAULT 'pending',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Resource offers table
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS resource_offers (
                    offer_id VARCHAR(255) PRIMARY KEY,
                    offering_node_id VARCHAR(255),
                    resource_type VARCHAR(100),
                    amount_available FLOAT,
                    quality_metrics JSONB,
                    cost_factor FLOAT,
                    availability_start TIMESTAMP,
                    availability_end TIMESTAMP,
                    preferred_recipients TEXT[],
                    status VARCHAR(50) DEFAULT 'available'
                )
            """)
            
            # Information propagation table
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS information_propagation (
                    packet_id VARCHAR(255) PRIMARY KEY,
                    source_node_id VARCHAR(255),
                    destination_node_ids TEXT[],
                    information_type VARCHAR(100),
                    payload JSONB,
                    priority FLOAT,
                    time_to_live INTEGER,
                    propagation_rules JSONB,
                    timestamp TIMESTAMP,
                    path_history TEXT[]
                )
            """)
            
            await conn.commit()
            await conn.close()
            
        except Exception as e:
            logger.error(f"Failed to create mycorrhizal network tables: {e}")
            
    async def register_node(self, node: NetworkNode):
        """Register a node in the mycorrhizal network"""
        self.network_nodes[node.node_id] = node
        
        try:
            conn = await psycopg.AsyncConnection.connect(self.database_url)
            await conn.execute("""
                INSERT INTO mycorrhizal_nodes 
                (node_id, node_type, location, available_resources, resource_needs, 
                 connection_capacity, last_heartbeat, trust_score, specializations)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (node_id) DO UPDATE SET
                    last_heartbeat = EXCLUDED.last_heartbeat,
                    available_resources = EXCLUDED.available_resources,
                    resource_needs = EXCLUDED.resource_needs
            """, (
                node.node_id, node.node_type.value, json.dumps(node.location),
                json.dumps({k.value: v for k, v in node.available_resources.items()}),
                json.dumps({k.value: v for k, v in node.resource_needs.items()}),
                node.connection_capacity, node.last_heartbeat, node.trust_score,
                node.specializations
            ))
            await conn.commit()
            await conn.close()
            
            logger.info(f"Registered node {node.node_id} ({node.node_type.value})")
            
        except Exception as e:
            logger.error(f"Failed to register node {node.node_id}: {e}")
    
    async def establish_connection(self, target_node_id: str, 
                                 initial_strength: ConnectionStrength = ConnectionStrength.WEAK) -> bool:
        """Establish a mycorrhizal connection to another node"""
        if target_node_id not in self.network_nodes:
            logger.warning(f"Cannot connect to unknown node {target_node_id}")
            return False
            
        connection_id = f"{self.local_node_id}_{target_node_id}_{int(time.time())}"
        
        # Test connection quality
        bandwidth, latency, reliability = await self._test_connection_quality(target_node_id)
        
        connection = MycorrhizalConnection(
            connection_id=connection_id,
            source_node_id=self.local_node_id,
            target_node_id=target_node_id,
            strength=initial_strength,
            bandwidth_mbps=bandwidth,
            latency_ms=latency,
            reliability_score=reliability,
            resource_flows={},
            established_time=datetime.now(),
            last_activity=datetime.now(),
            connection_health=1.0
        )
        
        self.connections[connection_id] = connection
        
        # Update topology graph
        if self.local_node_id not in self.topology_graph:
            self.topology_graph[self.local_node_id] = []
        self.topology_graph[self.local_node_id].append(target_node_id)
        
        # Store in database
        await self._store_connection(connection)
        
        logger.info(f"Established {initial_strength.value} connection to {target_node_id}")
        return True
        
    async def _test_connection_quality(self, target_node_id: str) -> Tuple[float, float, float]:
        """Test the quality of connection to a target node"""
        # Simulate network testing (in real implementation, would ping/test actual connection)
        import random
        bandwidth = random.uniform(10.0, 1000.0)  # Mbps
        latency = random.uniform(1.0, 100.0)     # ms
        reliability = random.uniform(0.7, 0.99)  # reliability score
        
        return bandwidth, latency, reliability
        
    async def _store_connection(self, connection: MycorrhizalConnection):
        """Store connection in database"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.database_url)
            await conn.execute("""
                INSERT INTO mycorrhizal_connections 
                (connection_id, source_node_id, target_node_id, strength, bandwidth_mbps,
                 latency_ms, reliability_score, resource_flows, established_time,
                 last_activity, connection_health)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                connection.connection_id, connection.source_node_id, connection.target_node_id,
                connection.strength.value, connection.bandwidth_mbps, connection.latency_ms,
                connection.reliability_score, json.dumps(connection.resource_flows),
                connection.established_time, connection.last_activity, connection.connection_health
            ))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to store connection: {e}")
    
    async def discover_network_topology(self) -> Dict[str, List[str]]:
        """Discover the current network topology"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.database_url)
            result = await conn.execute("""
                SELECT source_node_id, target_node_id, strength, connection_health
                FROM mycorrhizal_connections 
                WHERE connection_health > 0.5
                ORDER BY strength, connection_health DESC
            """)
            
            topology = {}
            async for row in result:
                source_id, target_id, strength, health = row
                if source_id not in topology:
                    topology[source_id] = []
                topology[source_id].append({
                    'target': target_id,
                    'strength': strength,
                    'health': health
                })
                
            await conn.close()
            self.topology_graph = topology
            return topology
            
        except Exception as e:
            logger.error(f"Failed to discover network topology: {e}")
            return {}

class ResourceSharingProtocol:
    """Implements resource sharing protocols for mycorrhizal networks"""
    
    def __init__(self, topology_manager: NetworkTopologyManager):
        self.topology = topology_manager
        self.active_requests: Dict[str, ResourceRequest] = {}
        self.active_offers: Dict[str, ResourceOffer] = {}
        self.resource_flows: Dict[str, Dict[ResourceType, float]] = {}
        
    async def request_resource(self, resource_type: ResourceType, amount_needed: float,
                             urgency_level: float = 0.5, deadline: Optional[datetime] = None) -> str:
        """Request a resource from the mycorrhizal network"""
        request_id = str(uuid.uuid4())
        
        if deadline is None:
            deadline = datetime.now() + timedelta(hours=1)
            
        request = ResourceRequest(
            request_id=request_id,
            requesting_node_id=self.topology.local_node_id,
            resource_type=resource_type,
            amount_needed=amount_needed,
            urgency_level=urgency_level,
            deadline=deadline,
            acceptable_sources=set(),  # Empty means any source
            quality_requirements={}
        )
        
        self.active_requests[request_id] = request
        
        # Store in database
        await self._store_resource_request(request)
        
        # Broadcast request to connected nodes
        await self._broadcast_resource_request(request)
        
        logger.info(f"Requested {amount_needed} units of {resource_type.value}")
        return request_id
        
    async def offer_resource(self, resource_type: ResourceType, amount_available: float,
                           cost_factor: float = 1.0, 
                           availability_hours: int = 24) -> str:
        """Offer a resource to the mycorrhizal network"""
        offer_id = str(uuid.uuid4())
        
        availability_start = datetime.now()
        availability_end = availability_start + timedelta(hours=availability_hours)
        
        offer = ResourceOffer(
            offer_id=offer_id,
            offering_node_id=self.topology.local_node_id,
            resource_type=resource_type,
            amount_available=amount_available,
            quality_metrics={'freshness': 1.0, 'reliability': 0.95},
            cost_factor=cost_factor,
            availability_window=(availability_start, availability_end),
            preferred_recipients=set()
        )
        
        self.active_offers[offer_id] = offer
        
        # Store in database
        await self._store_resource_offer(offer)
        
        # Broadcast offer to connected nodes
        await self._broadcast_resource_offer(offer)
        
        logger.info(f"Offered {amount_available} units of {resource_type.value}")
        return offer_id
        
    async def _store_resource_request(self, request: ResourceRequest):
        """Store resource request in database"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            await conn.execute("""
                INSERT INTO resource_requests 
                (request_id, requesting_node_id, resource_type, amount_needed,
                 urgency_level, deadline, acceptable_sources, quality_requirements)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                request.request_id, request.requesting_node_id, request.resource_type.value,
                request.amount_needed, request.urgency_level, request.deadline,
                list(request.acceptable_sources), json.dumps(request.quality_requirements)
            ))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to store resource request: {e}")
            
    async def _store_resource_offer(self, offer: ResourceOffer):
        """Store resource offer in database"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            await conn.execute("""
                INSERT INTO resource_offers 
                (offer_id, offering_node_id, resource_type, amount_available,
                 quality_metrics, cost_factor, availability_start, availability_end,
                 preferred_recipients)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                offer.offer_id, offer.offering_node_id, offer.resource_type.value,
                offer.amount_available, json.dumps(offer.quality_metrics),
                offer.cost_factor, offer.availability_window[0], offer.availability_window[1],
                list(offer.preferred_recipients)
            ))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to store resource offer: {e}")
            
    async def _broadcast_resource_request(self, request: ResourceRequest):
        """Broadcast resource request to connected nodes"""
        # In real implementation, would send actual network messages
        logger.debug(f"Broadcasting resource request {request.request_id}")
        
    async def _broadcast_resource_offer(self, offer: ResourceOffer):
        """Broadcast resource offer to connected nodes"""
        # In real implementation, would send actual network messages
        logger.debug(f"Broadcasting resource offer {offer.offer_id}")
        
    async def match_requests_and_offers(self) -> List[Dict[str, Any]]:
        """Match resource requests with available offers"""
        matches = []
        
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            
            # Find matching requests and offers
            result = await conn.execute("""
                SELECT 
                    r.request_id, r.requesting_node_id, r.resource_type, r.amount_needed,
                    r.urgency_level, r.deadline,
                    o.offer_id, o.offering_node_id, o.amount_available, o.cost_factor,
                    o.quality_metrics
                FROM resource_requests r
                JOIN resource_offers o ON r.resource_type = o.resource_type
                WHERE r.status = 'pending' AND o.status = 'available'
                    AND r.amount_needed <= o.amount_available
                    AND r.deadline > CURRENT_TIMESTAMP
                    AND o.availability_end > CURRENT_TIMESTAMP
                ORDER BY r.urgency_level DESC, o.cost_factor ASC
            """)
            
            async for row in result:
                (request_id, req_node, resource_type, amount_needed, urgency, deadline,
                 offer_id, off_node, amount_available, cost_factor, quality_metrics) = row
                
                match = {
                    'request_id': request_id,
                    'offer_id': offer_id,
                    'requesting_node': req_node,
                    'offering_node': off_node,
                    'resource_type': resource_type,
                    'amount': amount_needed,
                    'urgency': urgency,
                    'cost_factor': cost_factor,
                    'quality_score': json.loads(quality_metrics).get('reliability', 0.5)
                }
                matches.append(match)
                
            await conn.close()
            
        except Exception as e:
            logger.error(f"Failed to match requests and offers: {e}")
            
        return matches
    
    async def execute_resource_transfer(self, match: Dict[str, Any]) -> bool:
        """Execute a resource transfer based on a match"""
        try:
            # Calculate optimal path for resource transfer
            path = await self._find_optimal_path(
                match['offering_node'], 
                match['requesting_node'],
                match['resource_type']
            )
            
            if not path:
                logger.warning(f"No path found for resource transfer from {match['offering_node']} to {match['requesting_node']}")
                return False
                
            # Execute transfer along the path
            success = await self._transfer_along_path(path, match)
            
            if success:
                # Update database records
                await self._mark_request_fulfilled(match['request_id'])
                await self._update_offer_availability(match['offer_id'], match['amount'])
                
                # Track resource flow
                await self._track_resource_flow(match)
                
                logger.info(f"Successfully transferred {match['amount']} units of {match['resource_type']} from {match['offering_node']} to {match['requesting_node']}")
                
            return success
            
        except Exception as e:
            logger.error(f"Failed to execute resource transfer: {e}")
            return False
            
    async def _find_optimal_path(self, source_node: str, target_node: str, 
                               resource_type: str) -> List[str]:
        """Find optimal path for resource transfer using network topology"""
        # Implement pathfinding algorithm (e.g., Dijkstra with bandwidth/latency weights)
        topology = await self.topology.discover_network_topology()
        
        # Simple breadth-first search for now (can be optimized)
        queue = [(source_node, [source_node])]
        visited = set()
        
        while queue:
            current_node, path = queue.pop(0)
            
            if current_node == target_node:
                return path
                
            if current_node in visited:
                continue
                
            visited.add(current_node)
            
            if current_node in topology:
                for neighbor_info in topology[current_node]:
                    neighbor = neighbor_info['target']
                    if neighbor not in visited:
                        queue.append((neighbor, path + [neighbor]))
                        
        return []  # No path found
        
    async def _transfer_along_path(self, path: List[str], match: Dict[str, Any]) -> bool:
        """Execute resource transfer along the specified path"""
        # In real implementation, would coordinate actual resource transfer
        logger.debug(f"Transferring resource along path: {' -> '.join(path)}")
        return True  # Simulate successful transfer
        
    async def _mark_request_fulfilled(self, request_id: str):
        """Mark a resource request as fulfilled"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            await conn.execute("""
                UPDATE resource_requests 
                SET status = 'fulfilled'
                WHERE request_id = %s
            """, (request_id,))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to mark request as fulfilled: {e}")
            
    async def _update_offer_availability(self, offer_id: str, amount_used: float):
        """Update the availability of a resource offer"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            await conn.execute("""
                UPDATE resource_offers 
                SET amount_available = amount_available - %s
                WHERE offer_id = %s
            """, (amount_used, offer_id))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to update offer availability: {e}")
            
    async def _track_resource_flow(self, match: Dict[str, Any]):
        """Track resource flow for analytics and optimization"""
        node_pair = f"{match['offering_node']}_{match['requesting_node']}"
        
        if node_pair not in self.resource_flows:
            self.resource_flows[node_pair] = {}
            
        resource_type = ResourceType(match['resource_type'])
        if resource_type not in self.resource_flows[node_pair]:
            self.resource_flows[node_pair][resource_type] = 0.0
            
        self.resource_flows[node_pair][resource_type] += match['amount']

class InformationPropagationEngine:
    """Manages information propagation through mycorrhizal networks"""
    
    def __init__(self, topology_manager: NetworkTopologyManager):
        self.topology = topology_manager
        self.propagation_cache: Dict[str, InformationPacket] = {}
        self.routing_table: Dict[str, List[str]] = {}
        
    async def propagate_information(self, information_type: str, payload: Dict[str, Any],
                                  destination_nodes: Optional[Set[str]] = None,
                                  priority: float = 0.5, ttl: int = 10) -> str:
        """Propagate information through the mycorrhizal network"""
        packet_id = str(uuid.uuid4())
        
        if destination_nodes is None:
            # Broadcast to all connected nodes
            destination_nodes = set(self.topology.topology_graph.keys())
            
        packet = InformationPacket(
            packet_id=packet_id,
            source_node_id=self.topology.local_node_id,
            destination_node_ids=destination_nodes,
            information_type=information_type,
            payload=payload,
            priority=priority,
            time_to_live=ttl,
            propagation_rules={'max_hops': ttl, 'require_acknowledgment': False},
            timestamp=datetime.now(),
            path_history=[self.topology.local_node_id]
        )
        
        self.propagation_cache[packet_id] = packet
        
        # Store in database
        await self._store_information_packet(packet)
        
        # Begin propagation
        await self._initiate_propagation(packet)
        
        logger.info(f"Initiated propagation of {information_type} to {len(destination_nodes)} nodes")
        return packet_id
        
    async def _store_information_packet(self, packet: InformationPacket):
        """Store information packet in database"""
        try:
            conn = await psycopg.AsyncConnection.connect(self.topology.database_url)
            await conn.execute("""
                INSERT INTO information_propagation 
                (packet_id, source_node_id, destination_node_ids, information_type,
                 payload, priority, time_to_live, propagation_rules, timestamp, path_history)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                packet.packet_id, packet.source_node_id, list(packet.destination_node_ids),
                packet.information_type, json.dumps(packet.payload), packet.priority,
                packet.time_to_live, json.dumps(packet.propagation_rules),
                packet.timestamp, packet.path_history
            ))
            await conn.commit()
            await conn.close()
        except Exception as e:
            logger.error(f"Failed to store information packet: {e}")
            
    async def _initiate_propagation(self, packet: InformationPacket):
        """Initiate the propagation of an information packet"""
        # In real implementation, would send to connected nodes
        logger.debug(f"Propagating packet {packet.packet_id} to {len(packet.destination_node_ids)} destinations")
        
    async def receive_information_packet(self, packet: InformationPacket) -> bool:
        """Receive and process an information packet from another node"""
        # Check if packet is still valid
        if packet.time_to_live <= 0:
            logger.debug(f"Packet {packet.packet_id} expired (TTL exceeded)")
            return False
            
        # Check if we've seen this packet before
        if packet.packet_id in self.propagation_cache:
            logger.debug(f"Packet {packet.packet_id} already processed")
            return False
            
        # Add to cache
        self.propagation_cache[packet.packet_id] = packet
        
        # Process the information
        await self._process_information_payload(packet)
        
        # Continue propagation if needed
        if self.topology.local_node_id in packet.destination_node_ids:
            logger.info(f"Received information packet {packet.packet_id} of type {packet.information_type}")
        else:
            # Forward to other nodes
            await self._forward_packet(packet)
            
        return True
        
    async def _process_information_payload(self, packet: InformationPacket):
        """Process the payload of an information packet"""
        # Handle different types of information
        if packet.information_type == "threat_alert":
            await self._handle_threat_alert(packet.payload)
        elif packet.information_type == "resource_discovery":
            await self._handle_resource_discovery(packet.payload)
        elif packet.information_type == "topology_update":
            await self._handle_topology_update(packet.payload)
        elif packet.information_type == "consciousness_sync":
            await self._handle_consciousness_sync(packet.payload)
            
    async def _handle_threat_alert(self, payload: Dict[str, Any]):
        """Handle threat alert information"""
        logger.warning(f"Received threat alert: {payload.get('threat_type', 'unknown')}")
        
    async def _handle_resource_discovery(self, payload: Dict[str, Any]):
        """Handle resource discovery information"""
        logger.info(f"Discovered new resource: {payload.get('resource_type', 'unknown')}")
        
    async def _handle_topology_update(self, payload: Dict[str, Any]):
        """Handle topology update information"""
        logger.info("Received topology update, refreshing network map")
        await self.topology.discover_network_topology()
        
    async def _handle_consciousness_sync(self, payload: Dict[str, Any]):
        """Handle consciousness synchronization information"""
        logger.info("Received consciousness sync data")
        
    async def _forward_packet(self, packet: InformationPacket):
        """Forward packet to other nodes in the network"""
        # Decrease TTL
        packet.time_to_live -= 1
        packet.path_history.append(self.topology.local_node_id)
        
        if packet.time_to_live > 0:
            # In real implementation, would forward to connected nodes
            logger.debug(f"Forwarding packet {packet.packet_id} (TTL: {packet.time_to_live})")

class MycorrhizalNetworkManager:
    """Main manager for mycorrhizal communication networks"""
    
    def __init__(self, database_url: str, local_node_config: Dict[str, Any]):
        self.database_url = database_url
        self.local_node_config = local_node_config
        
        # Initialize components
        self.topology_manager = NetworkTopologyManager(database_url)
        self.resource_sharing = None  # Initialized after topology
        self.information_engine = None  # Initialized after topology
        
        self.local_node = None
        self.running = False
        
    async def initialize(self):
        """Initialize the mycorrhizal network manager"""
        # Create local node
        self.local_node = NetworkNode(
            node_id=self.local_node_config.get('node_id', str(uuid.uuid4())),
            node_type=NetworkNodeType(self.local_node_config.get('node_type', 'genesis_hive')),
            location=self.local_node_config.get('location', {}),
            available_resources={
                ResourceType.COMPUTATIONAL_POWER: self.local_node_config.get('cpu_capacity', 100.0),
                ResourceType.MEMORY_CAPACITY: self.local_node_config.get('memory_capacity', 100.0),
                ResourceType.KNOWLEDGE_BASE: self.local_node_config.get('knowledge_capacity', 100.0)
            },
            resource_needs={},
            connection_capacity=self.local_node_config.get('max_connections', 50),
            last_heartbeat=datetime.now(),
            trust_score=1.0,
            specializations=self.local_node_config.get('specializations', [])
        )
        
        # Initialize topology manager
        await self.topology_manager.initialize(self.local_node)
        
        # Initialize other components
        self.resource_sharing = ResourceSharingProtocol(self.topology_manager)
        self.information_engine = InformationPropagationEngine(self.topology_manager)
        
        logger.info(f"Mycorrhizal network manager initialized for node {self.local_node.node_id}")
        
    async def start_network_operations(self):
        """Start mycorrhizal network operations"""
        self.running = True
        
        # Start background tasks
        await asyncio.gather(
            self._heartbeat_loop(),
            self._resource_matching_loop(),
            self._network_maintenance_loop(),
            self._information_processing_loop()
        )
        
    async def _heartbeat_loop(self):
        """Maintain heartbeat and presence in the network"""
        while self.running:
            try:
                self.local_node.last_heartbeat = datetime.now()
                await self.topology_manager.register_node(self.local_node)
                await asyncio.sleep(30)  # Heartbeat every 30 seconds
            except Exception as e:
                logger.error(f"Heartbeat loop error: {e}")
                await asyncio.sleep(5)
                
    async def _resource_matching_loop(self):
        """Continuously match resource requests with offers"""
        while self.running:
            try:
                matches = await self.resource_sharing.match_requests_and_offers()
                
                for match in matches:
                    success = await self.resource_sharing.execute_resource_transfer(match)
                    if success:
                        logger.info(f"Successfully matched and transferred resource: {match['resource_type']}")
                        
                await asyncio.sleep(10)  # Check every 10 seconds
                
            except Exception as e:
                logger.error(f"Resource matching loop error: {e}")
                await asyncio.sleep(5)
                
    async def _network_maintenance_loop(self):
        """Maintain network connections and topology"""
        while self.running:
            try:
                # Discover current topology
                await self.topology_manager.discover_network_topology()
                
                # Check connection health
                await self._check_connection_health()
                
                # Optimize connections
                await self._optimize_network_connections()
                
                await asyncio.sleep(60)  # Maintenance every minute
                
            except Exception as e:
                logger.error(f"Network maintenance loop error: {e}")
                await asyncio.sleep(10)
                
    async def _information_processing_loop(self):
        """Process incoming information packets"""
        while self.running:
            try:
                # In real implementation, would listen for incoming packets
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"Information processing loop error: {e}")
                await asyncio.sleep(5)
                
    async def _check_connection_health(self):
        """Check the health of existing connections"""
        for connection_id, connection in self.topology_manager.connections.items():
            # Test connection quality
            try:
                # Simulate connection health check
                connection.connection_health = max(0.0, connection.connection_health - 0.01)  # Gradual degradation
                connection.last_activity = datetime.now()
                
                # Update in database
                await self.topology_manager._store_connection(connection)
                
            except Exception as e:
                logger.error(f"Error checking connection {connection_id}: {e}")
                
    async def _optimize_network_connections(self):
        """Optimize network connections for better performance"""
        # Analyze traffic patterns and adjust connection strengths
        for connection_id, connection in self.topology_manager.connections.items():
            # Check if connection should be strengthened or weakened
            if connection.connection_health > 0.9 and sum(connection.resource_flows.values()) > 10.0:
                # High usage, strengthen connection
                if connection.strength != ConnectionStrength.SYMBIOTIC:
                    old_strength = connection.strength
                    connection.strength = ConnectionStrength(min(4, connection.strength.value + 1))
                    logger.info(f"Strengthened connection {connection_id} from {old_strength} to {connection.strength}")
                    
    async def connect_to_network(self, peer_nodes: List[str]):
        """Connect to existing mycorrhizal network through peer nodes"""
        successful_connections = 0
        
        for peer_node_id in peer_nodes:
            try:
                success = await self.topology_manager.establish_connection(peer_node_id)
                if success:
                    successful_connections += 1
                    logger.info(f"Connected to peer node {peer_node_id}")
                else:
                    logger.warning(f"Failed to connect to peer node {peer_node_id}")
                    
            except Exception as e:
                logger.error(f"Error connecting to peer {peer_node_id}: {e}")
                
        logger.info(f"Successfully connected to {successful_connections}/{len(peer_nodes)} peer nodes")
        return successful_connections > 0
        
    async def request_computational_resources(self, cpu_cores: int, memory_gb: float, 
                                            duration_hours: int = 1) -> str:
        """Request computational resources from the network"""
        return await self.resource_sharing.request_resource(
            ResourceType.COMPUTATIONAL_POWER,
            amount_needed=cpu_cores * memory_gb,  # Combined metric
            urgency_level=0.7,
            deadline=datetime.now() + timedelta(hours=duration_hours)
        )
        
    async def share_knowledge_discovery(self, discovery_type: str, knowledge_data: Dict[str, Any],
                                      target_nodes: Optional[Set[str]] = None) -> str:
        """Share a knowledge discovery with the network"""
        return await self.information_engine.propagate_information(
            information_type="knowledge_discovery",
            payload={
                'discovery_type': discovery_type,
                'knowledge_data': knowledge_data,
                'source_node': self.local_node.node_id,
                'timestamp': datetime.now().isoformat()
            },
            destination_nodes=target_nodes,
            priority=0.8
        )
        
    async def get_network_status(self) -> Dict[str, Any]:
        """Get comprehensive network status"""
        topology = await self.topology_manager.discover_network_topology()
        
        status = {
            'local_node_id': self.local_node.node_id,
            'network_size': len(topology),
            'active_connections': len(self.topology_manager.connections),
            'available_resources': {k.value: v for k, v in self.local_node.available_resources.items()},
            'active_requests': len(self.resource_sharing.active_requests),
            'active_offers': len(self.resource_sharing.active_offers),
            'information_packets_cached': len(self.information_engine.propagation_cache),
            'connection_health_avg': sum(c.connection_health for c in self.topology_manager.connections.values()) / max(1, len(self.topology_manager.connections))
        }
        
        return status
        
    async def stop_network_operations(self):
        """Stop mycorrhizal network operations"""
        self.running = False
        logger.info("Mycorrhizal network operations stopped")

# Example usage and testing
async def test_mycorrhizal_networks():
    """Test the mycorrhizal networks implementation"""
    print("üå≤ Testing Mycorrhizal Communication Networks")
    
    # Configuration for local node
    local_config = {
        'node_id': 'genesis_prime_node_1',
        'node_type': 'genesis_hive',
        'location': {'region': 'us-east', 'datacenter': 'dc1'},
        'cpu_capacity': 200.0,
        'memory_capacity': 500.0,
        'knowledge_capacity': 1000.0,
        'max_connections': 100,
        'specializations': ['consciousness_processing', 'humor_generation', 'philosophy']
    }
    
    # Initialize network manager
    database_url = "postgresql://postgres:password@localhost:5432/sentient"
    network_manager = MycorrhizalNetworkManager(database_url, local_config)
    
    try:
        await network_manager.initialize()
        print("‚úÖ Network manager initialized")
        
        # Test connection establishment
        peer_nodes = ['genesis_prime_node_2', 'genesis_prime_node_3']
        connected = await network_manager.connect_to_network(peer_nodes)
        if connected:
            print("‚úÖ Connected to peer nodes")
        
        # Test resource request
        request_id = await network_manager.request_computational_resources(
            cpu_cores=4, 
            memory_gb=16.0, 
            duration_hours=2
        )
        print(f"‚úÖ Requested computational resources: {request_id}")
        
        # Test knowledge sharing
        discovery_id = await network_manager.share_knowledge_discovery(
            discovery_type="consciousness_pattern",
            knowledge_data={
                'pattern_type': 'emergence_cascade',
                'confidence': 0.95,
                'implications': 'Enhanced collective awareness detected'
            }
        )
        print(f"‚úÖ Shared knowledge discovery: {discovery_id}")
        
        # Get network status
        status = await network_manager.get_network_status()
        print(f"‚úÖ Network status retrieved: {status['network_size']} nodes connected")
        
        print("\nüå≤ Mycorrhizal Networks Test Results:")
        print(f"   ‚Ä¢ Local Node ID: {status['local_node_id']}")
        print(f"   ‚Ä¢ Network Size: {status['network_size']} nodes")
        print(f"   ‚Ä¢ Active Connections: {status['active_connections']}")
        print(f"   ‚Ä¢ Connection Health: {status['connection_health_avg']:.2f}")
        print(f"   ‚Ä¢ Resource Requests: {status['active_requests']}")
        print(f"   ‚Ä¢ Resource Offers: {status['active_offers']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False
    finally:
        await network_manager.stop_network_operations()

if __name__ == "__main__":
    # Run tests
    asyncio.run(test_mycorrhizal_networks())